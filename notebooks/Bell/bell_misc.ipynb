{
 "metadata": {
  "name": "",
  "signature": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "import os\n",
      "import datetime\n",
      "\n",
      "base_folder = r'D:\\measuring'\n",
      "\n",
      "if not base_folder in sys.path:\n",
      "    sys.path.append(base_folder)\n",
      "execfile(os.path.join(base_folder,r'analysis\\scripts\\setup_analysis.py'))\n",
      "execfile(os.path.join(base_folder,r'analysis\\scripts\\bell\\setup_bell_analysis.py'))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#here we get a list of files that actually contributed to the data ie had at least one entanglement event\n",
      "bs_folder = r'D:\\measuring\\data\\2015-06-28-lhfbt5\\BS'\n",
      "bs_folder_n = r'D:\\measuring\\data\\2015-12-08-lhfbt6-new_detector\\BS'\n",
      "bs_folder_o = r'D:\\measuring\\data\\2015-12-01-lhfbt6\\BS'\n",
      "bs_folders=[bs_folder]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.intersect1d?"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "correlation_matrix_sum  = np.zeros((4,4), dtype=np.int64)\n",
      "filter_invalid = False\n",
      "filter_psb = False\n",
      "use_local_files=False\n",
      "for bs_folder in bs_folders:\n",
      "    measurement_pattern = 'TheSecondFinal'\n",
      "    output_folder = os.path.split(bs_folder)[0]\n",
      "    analysis_fp = bell_data.get_latest_analysis_fp(output_folder, pattern ='total_events')\n",
      "    bs_fps, lt3_fps, lt4_fps = bell_data.get_unique_bell_fps_from_analysis_file(analysis_fp)\n",
      "\n",
      "    f = h5py.File(analysis_fp,'r')\n",
      "    db_fps=f['analysis']['total_ent_events_fps'].value\n",
      "    d3_fps=f['analysis']['total_lt3_ssro_fps'].value\n",
      "    d4_fps=f['analysis']['total_lt4_ssro_fps'].value\n",
      "    db = f['analysis']['total_ent_events'].value\n",
      "    d3 = f['analysis']['total_lt3_ssro'].value\n",
      "    d4 = f['analysis']['total_lt4_ssro'].value\n",
      "    f.close()\n",
      "    n=0\n",
      "    nm=0\n",
      "    correlation_matrix      = np.zeros((4,4), dtype=np.int64)\n",
      "\n",
      "    iii=0\n",
      "    print 'processing:', len(lt3_fps)\n",
      "    for fp3,fp4 in zip(lt3_fps[:],lt4_fps[:]):\n",
      "        if use_local_files:\n",
      "            fp3 = os.path.join(os.path.split(bs_folder)[0],'LT3',fp3[8:])\n",
      "            fp4 = os.path.join(os.path.split(bs_folder)[0],'LT4',fp4[8:])\n",
      "        print iii,\n",
      "        iii+=1\n",
      "        f3 = h5py.File(fp3,'r')\n",
      "        sn3 = f3['/PQ_sync_number-1'].value \n",
      "        sp3 = f3['/PQ_special-1'].value      \n",
      "        st3 = f3['/PQ_sync_time-1'].value\n",
      "        #tt3 = f3['/PQ_time-1'].value   \n",
      "        ch3 = f3['/PQ_channel-1'].value\n",
      "        f3.close()\n",
      "\n",
      "        f4 = h5py.File(fp4,'r')\n",
      "        sn4 = f4['/PQ_sync_number-1'].value \n",
      "        sp4 = f4['/PQ_special-1'].value      \n",
      "        st4 = f4['/PQ_sync_time-1'].value\n",
      "        #tt4 = f4['/PQ_time-1'].value   \n",
      "        ch4 = f4['/PQ_channel-1'].value\n",
      "        f4.close()\n",
      "\n",
      "        sn_diff_3= np.diff(sn3)\n",
      "        cut_idxs_3 = np.hstack(([0],np.where(sn_diff_3>1)[0],[len(sn3)]))\n",
      "        is_rnd_0_3 = (ch3&1==1) & (sp3==1)\n",
      "        is_rnd_1_3 = (ch3&2==2) & (sp3==1)\n",
      "        is_ro_0_3  = (sp3==0) & (ch3==0)  & (st3 > 10620)  & (st3 < (10620  + 3700))\n",
      "        is_inv_3   = (ch3&8==8) & (sp3==1)\n",
      "        is_tail_w1_3   = (sp3 == 0) & (ch3 == 0)  & (st3 > 7480)  & (st3 < (7480  + 200))\n",
      "        is_tail_w2_3   = (sp3 == 0) & (ch3 == 0)  & (st3 > 7480 + 350)  & (st3 < (7480  + 200 + 350))\n",
      "        is_tail_3      = is_tail_w1_3 | is_tail_w2_3\n",
      "\n",
      "        sn_ma_3    = sn3[(ch3&4==4) & (sp3==1)]\n",
      "        sn_cut3    = sn3[sn_diff_3>1]\n",
      "\n",
      "        sn_diff_4  = np.diff(sn4)\n",
      "        cut_idxs_4 = np.hstack(([0],np.where(sn_diff_4>2)[0],[len(sn4)])) #2 because additional sync every 250 el!\n",
      "        is_rnd_0_4 = (ch4&1==1) & (sp4==1)\n",
      "        is_rnd_1_4 = (ch4&2==2) & (sp4==1)\n",
      "        is_ro_0_4  = (sp4==0) & (ch4==0)  & (st4 > 10620)  & (st4 < (10620  + 3700))  \n",
      "        is_inv_4   = (ch4&8==8) & (sp4==1)\n",
      "        is_tail_w1_4   = (sp4 == 0) & (ch4 == 0)  & (st4 > 5350)  & (st4 < (5350  + 200))\n",
      "        is_tail_w2_4   = (sp4 == 0) & (ch4 == 0)  & (st4 > 5350 + 350)  & (st4 < (5350  + 200 + 350))\n",
      "        is_tail_4      = is_tail_w1_4 | is_tail_w2_4\n",
      "        sn_ma_4    = sn4[(ch4&4==4) & (sp4==1)]\n",
      "        sn_cut4    = sn4[sn_diff_4>2]\n",
      "\n",
      "        if len(cut_idxs_3)!=len(cut_idxs_4):\n",
      "            print 'Cut index error!'\n",
      "            print 'cuts:', len(cut_idxs_3), len(cut_idxs_4)\n",
      "            #print 'markers in analysis', len(sn_mas_3[d3_fps == fp3])+1, len(sn_mas_4[d4_fps == fp4])+1\n",
      "            print 'markers in files',len(sn_ma_3),len(sn_ma_4)\n",
      "            if len(sn_ma_3)-len(sn_ma_4)==1:\n",
      "                print 'fix last strategy 3'\n",
      "                print sn_ma_3[-2], float(sn_ma_4[-1])*250/251.\n",
      "                cut_idxs_3 = np.hstack(([0],np.where(sn_diff_3>1)[0][:-1],[len(sn3)]))\n",
      "                print fp3[-20:]\n",
      "            elif len(sn_ma_4)-len(sn_ma_3)==1:\n",
      "                print 'fix last strategy 4'\n",
      "                print sn_ma_3[-1], float(sn_ma_4[-2])*250/251.\n",
      "                cut_idxs_4 = np.hstack(([0],np.where(sn_diff_4>2)[0][:-1],[len(sn4)])) #2 because additional sync every 250 el!\n",
      "                print fp4[-20:]\n",
      "            else:\n",
      "                #print sn_ma_3\n",
      "                #print sn_cut3\n",
      "                #print sn_ma_4\n",
      "                #print sn_cut4\n",
      "                print 'skipping file'\n",
      "                print fp3[-20:], fp4[-20:]\n",
      "                continue\n",
      "        cuts = len(cut_idxs_3)\n",
      "\n",
      "        for i in range(cuts-1):\n",
      "            cur_cut_idx_l3=cut_idxs_3[i]+1\n",
      "            cur_cut_idx_u3=cut_idxs_3[i+1]\n",
      "            #print sn_ma_3,sn3[cur_cut_idx_l3],sn3[cur_cut_idx_u3-1]\n",
      "            cur_sn_3 =  sn3[cur_cut_idx_l3:cur_cut_idx_u3].astype(np.int64)-sn_ma_3[(sn_ma_3>sn3[cur_cut_idx_l3]) & (sn_ma_3<=sn3[cur_cut_idx_u3-1])][0]\n",
      "\n",
      "            cur_inv_sn_3   = cur_sn_3[is_inv_3[cur_cut_idx_l3:cur_cut_idx_u3]] \n",
      "            no_inv_fltr_3 = np.ones(len(cur_sn_3), dtype=np.bool)\n",
      "            if filter_invalid:\n",
      "                for inv_ev_sn in cur_inv_sn_3:\n",
      "                    diff_inv_ev = np.array(cur_sn_3.astype(np.int64) - inv_ev_sn, dtype=np.int64)\n",
      "                    no_inv_fltr_3 = no_inv_fltr_3 & ((diff_inv_ev <= 0) | (diff_inv_ev > 250))\n",
      "            if filter_psb:\n",
      "                no_psb_fltr_3 = np.logical_not(np.in1d(cur_sn_3,cur_sn_3[is_tail_3[cur_cut_idx_l3:cur_cut_idx_u3]]))\n",
      "            else:\n",
      "                no_psb_fltr_3 = True\n",
      "\n",
      "            cur_rnd_0_sn_3 = cur_sn_3[is_rnd_0_3[cur_cut_idx_l3:cur_cut_idx_u3] & no_inv_fltr_3 & no_psb_fltr_3]\n",
      "            cur_rnd_1_sn_3 = cur_sn_3[is_rnd_1_3[cur_cut_idx_l3:cur_cut_idx_u3] & no_inv_fltr_3 & no_psb_fltr_3]\n",
      "            cur_ro_0_sn_3  = cur_sn_3[is_ro_0_3[cur_cut_idx_l3:cur_cut_idx_u3]  & no_inv_fltr_3 & no_psb_fltr_3]\n",
      "            cur_ro_1_sn_3  = np.setdiff1d(np.union1d(cur_rnd_0_sn_3,cur_rnd_1_sn_3),cur_ro_0_sn_3)\n",
      "\n",
      "            cur_cut_idx_l4=cut_idxs_4[i]+1\n",
      "            cur_cut_idx_u4=cut_idxs_4[i+1]\n",
      "            cur_sn_4 =  sn4[cur_cut_idx_l4:cur_cut_idx_u4].astype(np.int64)-sn_ma_4[(sn_ma_4>sn4[cur_cut_idx_l4]) & (sn_ma_4<=sn4[cur_cut_idx_u4-1])][0]\n",
      "            cur_sn_cr_sns=cur_sn_4[np.where(np.diff(cur_sn_4)>1)[0]+1]\n",
      "            try:\n",
      "                last_cr_sn=cur_sn_cr_sns[(cur_sn_cr_sns>-251) & (cur_sn_cr_sns<=0)][0]\n",
      "            except:\n",
      "                print 'LT4 sync correction issue, skipping to next event'\n",
      "                continue\n",
      "                #last_cr_sn=cur_sn_cr_sns[(cur_sn_cr_sns>-251*2) & (cur_sn_cr_sns<=-251)][0]\n",
      "\n",
      "            #print cur_sn_4[(cur_sn_4>-551)&(cur_sn_4<-370)]\n",
      "            cur_sn_4_corr=cur_sn_4-(cur_sn_4-last_cr_sn)/251\n",
      "            #print cur_sn_4_corr[(cur_sn_4_corr>-551)&(cur_sn_4_corr<=-370)]\n",
      "            if np.sum(np.diff(cur_sn_4_corr)>1):\n",
      "                print 'LT4 sync correction error, skipping to next event'\n",
      "                continue\n",
      "            #cur_sn_4 = cur_sn_4_corr\n",
      "            #print cur_sn_4\n",
      "           # print cur_sn_4_corr\n",
      "            #if len(cur_sn_cut_idxs_4)>2:\n",
      "            #    \n",
      "            #    for j in range(len(cur_sn_cut_idxs_4)):\n",
      "            #        cur_sn_4_sub = cur_sn_4[cur_sn_cut_idxs_4[j]+1:cur_sn_cut_idxs_4[j+1]]\n",
      "            ##        if cur_sn_4_sub[0]<0 and cur_sn_4_sub[-1]>0:\n",
      "             #           print 'subselected', len(np.unique(cur_sn_4_sub)),'/',len(np.unique(cur_sn_4))\n",
      "             ##           cur_sn_4 = cur_sn_4_sub\n",
      "              #          cur_cut_idx_l4=cur_sn_cut_idxs_4[j]+1\n",
      "              #          cur_cut_idx_u4=cur_sn_cut_idxs_4[j+1]\n",
      "              #          break\n",
      "\n",
      "            cur_inv_sn_4   = cur_sn_4_corr[is_inv_4[cur_cut_idx_l4:cur_cut_idx_u4]]\n",
      "            no_inv_fltr_4 = np.ones(len(cur_sn_4_corr), dtype=np.bool)\n",
      "            if filter_invalid:\n",
      "                for inv_ev_sn in cur_inv_sn_4:\n",
      "                    diff_inv_ev = np.array(cur_sn_4_corr.astype(np.int64) - inv_ev_sn, dtype=np.int64)\n",
      "                    no_inv_fltr_4 = no_inv_fltr_4 & ((diff_inv_ev <= 0) | (diff_inv_ev > 250))\n",
      "            if filter_psb:\n",
      "                no_psb_fltr_4 = np.logical_not(np.in1d(cur_sn_4_corr,cur_sn_4_corr[is_tail_4[cur_cut_idx_l4:cur_cut_idx_u4]]))\n",
      "            else:\n",
      "                no_psb_fltr_4 = True\n",
      "            cur_rnd_0_sn_4 = cur_sn_4_corr[is_rnd_0_4[cur_cut_idx_l4:cur_cut_idx_u4] & no_inv_fltr_4 & no_psb_fltr_4]\n",
      "            cur_rnd_1_sn_4 = cur_sn_4_corr[is_rnd_1_4[cur_cut_idx_l4:cur_cut_idx_u4] & no_inv_fltr_4 & no_psb_fltr_4]\n",
      "            cur_ro_0_sn_4  = cur_sn_4_corr[is_ro_0_4[cur_cut_idx_l4:cur_cut_idx_u4] & no_inv_fltr_4 & no_psb_fltr_4]\n",
      "            cur_ro_1_sn_4  = np.setdiff1d(np.union1d(cur_rnd_0_sn_4,cur_rnd_1_sn_4),cur_ro_0_sn_4)\n",
      "                \n",
      "            n_cur = len(np.intersect1d(cur_sn_3[no_inv_fltr_3 & no_psb_fltr_3],cur_sn_4_corr[no_inv_fltr_4 & no_psb_fltr_4]))\n",
      "            n+=n_cur\n",
      "            #print n_cur, cur_sn_3[-1] - cur_sn_3[0]+1, cur_sn_4_corr[-1] - cur_sn_4_corr[0]+1\n",
      "            #print cur_sn_3[-1]-cur_sn_3[0],cur_sn_4[-1]-cur_sn_4[0],n_cur\n",
      "            inputs_ab  = [[cur_rnd_0_sn_3,cur_rnd_0_sn_4],\n",
      "                          [cur_rnd_0_sn_3,cur_rnd_1_sn_4],\n",
      "                          [cur_rnd_1_sn_3,cur_rnd_0_sn_4],\n",
      "                          [cur_rnd_1_sn_3,cur_rnd_1_sn_4]] #'RND (a,b) = (0,0); (0,1); (1,0); (1,1); '\n",
      "            outputs_xy = [[cur_ro_0_sn_3,cur_ro_0_sn_4],\n",
      "                          [cur_ro_0_sn_3,cur_ro_1_sn_4],\n",
      "                          [cur_ro_1_sn_3,cur_ro_0_sn_4],\n",
      "                          [cur_ro_1_sn_3,cur_ro_1_sn_4]]  #'RO (x,y) = (+1,+1); (+1,-1); (-1,+1); (-1,-1); \n",
      "            for ii,(a,b) in enumerate(inputs_ab):\n",
      "                for jj,(x,y) in enumerate(outputs_xy):\n",
      "                    correlation_matrix[ii,jj] +=  len(reduce(np.intersect1d, (a,b,x,y)))\n",
      "            #print len(np.setdiff1d(np.union1d(cur_rnd_0_sn,cur_rnd_1_sn),cur_sn))\n",
      "            #print cur_sn_3\n",
      "\n",
      "            ###Truetime_check\n",
      "            #some_cur_sn_3=-2000\n",
      "            #print some_cur_sn_3\n",
      "            #corresponding_cur_sn_4=cur_sn_4[cur_sn_4_corr==some_cur_sn_3][0]\n",
      "            #print corresponding_cur_sn_4\n",
      "            #t3= tt3[(sn3==sn_ma_3)&(sp3==1)&((ch3==1)|(ch3==2))]- tt3[(sn3==some_cur_sn_3+sn_ma_3)&(sp3==1)&((ch3==1)|(ch3==2))]\n",
      "            #t4= tt4[(sn4==sn_ma_4)&(sp4==1)&((ch4==1)|(ch4==2))]-tt4[(sn4==corresponding_cur_sn_4+sn_ma_4)&(sp4==1)&((ch4==1)|(ch4==2))]\n",
      "            #print t3.astype(np.int64)-t4.astype(np.int64)\n",
      "            #break\n",
      "    correlation_matrix_sum+=correlation_matrix\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fp3=lt3_fps[12]\n",
      "f3 = h5py.File(fp3,'r')\n",
      "sn3 = f3['/PQ_sync_number-1'].value \n",
      "sp3 = f3['/PQ_special-1'].value      \n",
      "st3 = f3['/PQ_sync_time-1'].value\n",
      "#tt3 = f3['/PQ_time-1'].value   \n",
      "ch3 = f3['/PQ_channel-1'].value\n",
      "f3.close()\n",
      "is_rnd_0_3 = (ch3&1==1) & (sp3==1)\n",
      "is_rnd_1_3 = (ch3&2==2) & (sp3==1)\n",
      "np.sum(is_rnd_0_3 & is_rnd_1_3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for sni in np.setdiff1d(sn3,sn3[is_rnd_0_3 | is_rnd_1_3]):\n",
      "    print sni\n",
      "    print ch3[sn3==sni]\n",
      "    print st3[sn3==sni]\n",
      "    print sp3[sn3==sni]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.setdiff1d(sn4,sn4[is_rnd_0_4 | is_rnd_1_4])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print n\n",
      "print np.sum(correlation_matrix_sum)\n",
      "print 2*(n-np.sum(correlation_matrix_sum)),nm\n",
      "print 'xy     ++,+-,-+,--'\n",
      "print 'ab 00', correlation_matrix_sum[0], '  (0,    -3pi/4)'\n",
      "print 'ab 01', correlation_matrix_sum[1], '  (0,    +3pi/4)'\n",
      "print 'ab 10', correlation_matrix_sum[2], '  (pi/2, -3pi/4)'\n",
      "print 'ab 11', correlation_matrix_sum[3], '  (pi/2, +3pi/4)\\n'\n",
      "print np.sum(correlation_matrix_sum, axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n00,n01,n10,n11 = np.sum(correlation_matrix_sum,axis=1)\n",
      "n=np.sum(correlation_matrix_sum)\n",
      "print n,n00,n01,n10,n11\n",
      "print n-n00-n01-n10-n11"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nt=n00+n01+n10+n11\n",
      "print float(n00)/nt-0.25, float(n01)/nt-0.25, float(n10)/nt-0.25, float(n11)/nt-0.25\n",
      "print 1/(2.*np.sqrt(nt))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fp1=r'D:\\measuring\\data\\2015-06-28-lhfbt5\\20150826111005_total_events.hdf5'\n",
      "fp2=r'D:\\measuring\\data\\2015-06-28-lhfbt5\\20160216112607_total_events.hdf5'\n",
      "fp = r'D:\\measuring\\data\\2015-12-08-lhfbt6-new_detector\\20160104210012_total_events.hdf5'\n",
      "f = h5py.File(fp1,'r')\n",
      "db_fps1=f['analysis']['total_ent_events_fps'].value\n",
      "db1 = f['analysis']['total_ent_events'].value\n",
      "d31 = f['analysis']['total_lt3_ssro'].value\n",
      "d41 = f['analysis']['total_lt4_ssro'].value\n",
      "f.close()\n",
      "f = h5py.File(fp2,'r')\n",
      "db_fps2=f['analysis']['total_ent_events_fps'].value\n",
      "db2 = f['analysis']['total_ent_events'].value\n",
      "d32 = f['analysis']['total_lt3_ssro'].value\n",
      "d42 = f['analysis']['total_lt4_ssro'].value\n",
      "f.close()\n",
      "f = h5py.File(fp,'r')\n",
      "db_fps=f['analysis']['total_ent_events_fps'].value\n",
      "db = f['analysis']['total_ent_events'].value\n",
      "d3 = f['analysis']['total_lt3_ssro'].value\n",
      "d4 = f['analysis']['total_lt4_ssro'].value\n",
      "f.close()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rng=d3[:,be._cl_noof_rnd_0] + d3[:,be._cl_noof_rnd_1]\n",
      "print np.min(rng),np.max(rng)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pts=10\n",
      "print cur_sn[0:pts]\n",
      "print cur_rnd_0_sn[0:pts]\n",
      "print cur_rnd_1_sn[0:pts]\n",
      "print len(np.setdiff1d(np.union1d(cur_rnd_0_sn,cur_rnd_1_sn),cur_sn))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fp= r'D:\\measuring\\data\\2015-11-16_XX\\BS\\20151122\\150414_Bell_lt4_MeasXX_moreXX_day5_run2\\150414_Bell_lt4_MeasXX_moreXX_day5_run2.hdf5'\n",
      "fp = r'Z:\\data\\20151122\\150218_Bell_BS_MeasXX_moreXX_day5_run2\\150218_Bell_BS_MeasXX_moreXX_day5_run2.hdf5'\n",
      "#fp = r'Z:\\data\\20151120\\150158_Bell_BS_MeasXX_moreXX_day4_run1\\150158_Bell_BS_MeasXX_moreXX_day4_run1.hdf5'\n",
      "#fp=r'Z:\\data\\20151120\\154451_Bell_BS_MeasXX_moreXX_day4_run2\\154451_Bell_BS_MeasXX_moreXX_day4_run2.hdf5'\n",
      "#fp=r'Z:\\data\\20151122\\140427_Bell_BS_SPCORR_ZPL_SPCORR_lt3\\140427_Bell_BS_SPCORR_ZPL_SPCORR_lt3.hdf5'\n",
      "#fp=r'Y:\\data\\20151122\\140624_Bell_lt3_SPCORR_ZPL_SPCORR_lt3\\140624_Bell_lt3_SPCORR_ZPL_SPCORR_lt3.hdf5'\n",
      "#fp = r'D:\\measuring\\data\\2015-11-16_XX\\BS\\20151123\\000633_Bell_lt4_MeasXX_moreXX_day5_run13\\000633_Bell_lt4_MeasXX_moreXX_day5_run13.hdf5'\n",
      "#fp = r'Z:\\data\\20151123\\181301_Bell_BS_SPCORR_ZPL_SPCORR_lt3\\181301_Bell_BS_SPCORR_ZPL_SPCORR_lt3.hdf5'\n",
      "f = h5py.File(fp,'r')\n",
      "sn = f['/PQ_sync_number-1'].value \n",
      "sp = f['/PQ_special-1'].value      \n",
      "st = f['/PQ_sync_time-1'].value\n",
      "tt = f['/PQ_time-1'].value   \n",
      "ch = f['/PQ_channel-1'].value\n",
      "f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ma_fltr = (sp==1)&((ch ==1))\n",
      "ms_sns=sn[ma_fltr]\n",
      "print sn[-1]\n",
      "print np.sum(ma_fltr)\n",
      "print len(np.unique(ms_sns))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sn1 = ms_sns[5]\n",
      "sn1idx=np.where((sn==sn1) & (sp==1))[0][0]\n",
      "rng=10\n",
      "print '    sync_nr   s_time sp ch  time[ns]'\n",
      "for i in range(sn1idx-rng,sn1idx+rng):\n",
      "    print ('-' if i == sn1idx else ' '),\n",
      "        \n",
      "    print '{:10d} '.format(sn[i]), '{:8d}'.format(st[i]),\\\n",
      "          ' {:d}'.format(sp[i]),' {:d}'.format(ch[i]),'  {:f}'.format(tt[i]/1e3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.union1d?"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "    \n",
      "    \n",
      "\n",
      "i=0\n",
      "bins=np.linspace(5950,6000,3000)\n",
      "tot_hist_0 = np.zeros(len(bins), dtype=np.uint32)[:-1]\n",
      "tot_hist_1 = np.zeros(len(bins), dtype=np.uint32)[:-1]\n",
      "mm=0\n",
      "chs=[]\n",
      "print len(bs_fps)\n",
      "for fp in bs_fps[:]:\n",
      "        f=h5py.File(fp,'r')\n",
      "        print '{}'.format(i),\n",
      "        i+=1\n",
      "        sn = f['/PQ_sync_number-1'].value \n",
      "        sp = f['/PQ_special-1'].value      \n",
      "        #st = f['/PQ_sync_time-1'].value\n",
      "        #_PQ_time = f['/PQ_time'].value   \n",
      "        ch = f['/PQ_channel-1'].value\n",
      "        f.close()\n",
      "        is_ent_marker = (sp==1) & (ch&1==1)\n",
      "        is_marker = (sp==1)\n",
      "        ent_marker_sn = sn[is_ent_marker]\n",
      "        ent_marker_sn_p1=ent_marker_sn+1\n",
      "        ent_marker_sn_p2=ent_marker_sn+2\n",
      "        marker_sn=sn[is_marker]\n",
      "        markers_not_ent_sn=np.setdiff1d(marker_sn,np.union1d(np.union1d(ent_marker_sn,ent_marker_sn_p1),ent_marker_sn_p2))\n",
      "        if len(markers_not_ent_sn)>0:\n",
      "            print fp[-20:]\n",
      "            print ent_marker_sn\n",
      "            print marker_sn\n",
      "            print markers_not_ent_sn\n",
      "            print [ch[(sn==mnesn)&(sp==1)] for mnesn in markers_not_ent_sn]\n",
      "            print '-'*40\n",
      "    \n",
      "    #hist_0,_x = np.histogram(st[(ch==1) & (sp==1)]/1000., bins=bins)\n",
      "    #hist_1,_x = np.histogram(st[(ch==2) & (sp==1)], bins=bins)\n",
      "    #tot_hist_0+=hist_0\n",
      "    #tot_hist_1+=hist_1\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print chs[0]\n",
      "print sum([np.sum(a&1==1) for a in chs])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'noof ch0', np.sum(tot_hist_0)\n",
      "#print 'noof ch1', np.sum(tot_hist_1)\n",
      "#print 'bias ch0/ch1-1: {:.6f} +\\- {:.6f}'.format(np.sum(tot_hist_0)/float(np.sum(tot_hist_1))-1,\n",
      "                                           #1./np.sqrt(np.sum(tot_hist_0)+float(np.sum(tot_hist_1))))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig, ax0 = plt.subplots(1,1, figsize=(4,3))    \n",
      "ax0.plot(_x[1:],tot_hist_0, drawstyle='steps-post', label='ch0')\n",
      "#ax0.plot(_x[1:],tot_hist_1, drawstyle='steps-post', label='ch1')\n",
      "#ax0.set_xlim(10350,10400)\n",
      "ax0.legend()\n",
      "ax0.set_title('BS ENT markers')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bs_folder = r'D:\\measuring\\data\\2015-06-28-lhfbt5\\LT4'\n",
      "measurement_pattern = 'Bell_lt4'\n",
      "fps = tb.get_all_msmt_filepaths(bs_folder, pattern=measurement_pattern)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bs_folder = r'D:\\measuring\\data\\2015-11-16_XX\\BS'\n",
      "measurement_pattern = 'moreXX'\n",
      "output_folder = os.path.split(bs_folder)[0]\n",
      "analysis_fp = bell_data.get_latest_analysis_fp(output_folder, pattern ='total_events')\n",
      "bs_fps, lt3_fps, lt4_fps = bell_data.get_unique_bell_fps_from_analysis_file(analysis_fp)\n",
      "\n",
      "fps = lt3_fps"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "i=0\n",
      "noof_0s=0\n",
      "noof_1s=0\n",
      "noof_rnd=0\n",
      "auto_corr_size= 50\n",
      "auto_corr = np.zeros(auto_corr_size, dtype=np.int)\n",
      "print len(fps)\n",
      "bins=np.linspace(0,15000,1500)\n",
      "for fp in fps[:]:\n",
      "    f=h5py.File(fp,'r')\n",
      "    #if i%10 == 0:\n",
      "    print '{}'.format(i),\n",
      "    i+=1\n",
      "    sn = f['/PQ_sync_number-1'].value \n",
      "    sp = f['/PQ_special-1'].value      \n",
      "    st = f['/PQ_sync_time-1'].value\n",
      "    #_PQ_time = f['/PQ_time'].value   \n",
      "    ch = f['/PQ_channel-1'].value\n",
      "    f.close()\n",
      "    fltr_rnd0 = (sp==1)&(ch==1)\n",
      "    fltr_rnd1 = (sp==1)&(ch==2)\n",
      "    good_rnd0=np.logical_not(np.in1d(sn[fltr_rnd0],sn[fltr_rnd1]))\n",
      "    good_rnd1=np.logical_not(np.in1d(sn[fltr_rnd1],sn[fltr_rnd0]))\n",
      "    noof_0s+= np.sum(good_rnd0)\n",
      "    noof_1s+= np.sum(good_rnd1)\n",
      "    fltr_rnd = (fltr_rnd0 | fltr_rnd1)\n",
      "    noof_rnd+=np.sum(fltr_rnd)\n",
      "    #rnd = ch[fltr_rnd]==2\n",
      "    #rnd_pm1=np.ones(len(rnd),dtype=np.int)\n",
      "    #rnd_pm1[rnd]=-1\n",
      "    #x=rnd_pm1\n",
      "    #corr = np.correlate(x, x, mode='full')\n",
      "    #auto_corr+=corr[corr.size/2:corr.size/2+auto_corr_size]\n",
      "    #for j in np.arange(auto_corr_size):\n",
      "        #print np.corrcoef(np.array([x[0:len(x)-j], x[j:len(x)]]))\n",
      "        #auto_corr[j] = np.corrcoef(np.array([x[0:len(x)-j], x[j:len(x)]]))\n",
      "    #    auto_corr[j] += np.sum(x[0:len(x)-j]*x[j:len(x)])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print bs_folder, measurement_pattern\n",
      "print 'noof ch0', noof_0s\n",
      "print 'noof ch1', noof_1s\n",
      "print 'bias ch0/ch1-1: {:.6f} +\\- {:.6f} (1 sigma)'.format(noof_0s/float(noof_1s+noof_0s)-0.5,\n",
      "                                           0.5*1./np.sqrt(noof_0s+noof_1s))\n",
      "print 'noof bad rnd', noof_rnd-noof_0s-noof_1s"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plot(auto_corr[1:]/float(auto_corr[0]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "i=0\n",
      "print len(fps)\n",
      "bins = np.arange(1,15001)\n",
      "total_rnd_st = []\n",
      "total_ph_st = []\n",
      "\n",
      "hist_rnd = np.zeros(len(bins)-1)\n",
      "hist_ph = np.zeros(len(bins)-1)\n",
      "hist_ent = np.zeros(len(bins)-1)\n",
      "hist_inv = np.zeros(len(bins)-1)\n",
      "for fp in fps[:]:\n",
      "    f=h5py.File(fp,'r')\n",
      "    print '{}'.format(i),\n",
      "    i+=1\n",
      "    #sn = f['/PQ_sync_number-1'].value \n",
      "    sp = f['/PQ_special-1'].value      \n",
      "    st = f['/PQ_sync_time-1'].value\n",
      "    #_PQ_time = f['/PQ_time'].value   \n",
      "    ch = f['/PQ_channel-1'].value\n",
      "    f.close()\n",
      "    fltr_ph = (sp == 0) & (ch==0)\n",
      "    fltr_ch0 = (ch==1)\n",
      "    fltr_ch1 = (ch==2)\n",
      "    fltr_rnd = (sp==1) &(fltr_ch0 | fltr_ch1)\n",
      "    fltr_ent = (sp==1) & (ch==4)\n",
      "    fltr_inv = (sp==1) & (ch==8)\n",
      "\n",
      "    hi_rnd, bins_h = np.histogram(st[fltr_rnd], bins)\n",
      "    hi_ph, bins_h  = np.histogram(st[fltr_ph], bins)\n",
      "    hi_ent, bins_h = np.histogram(st[fltr_ent], bins)\n",
      "    hi_inv, bins_h = np.histogram(st[fltr_inv], bins)\n",
      "    hist_rnd += hi_rnd\n",
      "    hist_ph  += hi_ph\n",
      "    hist_ent += hi_ent\n",
      "    hist_inv += hi_inv\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fp=r'D:\\measuring\\data\\2015-06-28-lhfbt5\\hists_lt4.npz'\n",
      "np.savez(fp,bins_h=bins,hist_rnd=hist_rnd,hist_ph=hist_ph,hist_ent=hist_ent,hist_inv=hist_inv) \n",
      "arr=np.vstack((bins[:-1],hist_rnd,hist_ph, hist_ent, hist_inv))\n",
      "np.savetxt(os.path.splitext(fp)[0]+'.txt', arr.T)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a=np.load(fp)\n",
      "a['hist_inv']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.histogram?"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t_start = 10e3\n",
      "t_end = 15e3\n",
      "fltr_ph = (sp == 0) & (ch==0)\n",
      "fltr_ch0 = (ch==1)\n",
      "fltr_ch1 = (ch==2)\n",
      "fltr_rnd = (sp==1) &(fltr_ch0 | fltr_ch1)\n",
      "fltr_time = (st>t_start ) & (st<t_end)\n",
      "rnd_st = st[fltr_time  & fltr_rnd]\n",
      "ph_st = st[fltr_time & fltr_ph]\n",
      "print test[:20]\n",
      "bins = np.linspace(t_start, t_end, 1000)\n",
      "hist_rnd, bins_h = np.histogram(test, bins)\n",
      "plt.hist(rnd_st, bins)\n",
      "plt.hist(ph_st, bins)\n",
      "#fig, ax0 = plt.subplots(1,1, figsize=(4,3))    \n",
      "#ax0.plot(bins, hist_rnd)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#np.savetxt('rnd.txt',total_rnd_st)\n",
      "np.savetxt('photons2.txt', total_ph_st)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig, ax0 = plt.subplots(1,1, figsize=(4,3))    \n",
      "ax0.plot(auto_corr[1:].astype(np.float)/auto_corr[0], drawstyle='steps-post')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print measurement_pattern\n",
      "print 'noof ch0', noof_0s\n",
      "print 'noof ch1', noof_1s\n",
      "print 'bias ch0/ch1-1: {:.6f} +\\- {:.6f}'.format(noof_0s/float(noof_1s)-1,\n",
      "                                           1./np.sqrt(noof_0s+noof_1s))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import shutil\n",
      "def collect_lt_data(bs_folder, lt3_source_folder, lt4_source_folder, measurement_pattern):\n",
      "    fps_bs = tb.get_all_msmt_filepaths(bs_folder, pattern=measurement_pattern)\n",
      "    print 'Found {} filepaths'.format(len(fps_bs))\n",
      "    target_folder = os.path.split(bs_folder)[0]\n",
      "    fps_lt3, fps_lt4 = bell_data.get_lt_fps(fps_bs, lt3_source_folder, lt4_source_folder)\n",
      "    print 'Found {},{} LT3,4 filepaths'.format(len(fps_lt3),len(fps_lt4))\n",
      "    skipped_fps=[]\n",
      "    for target_name, fps in zip(['LT3','LT4'],[fps_lt3,fps_lt4]):\n",
      "        print 'copying {} files'.format(target_name)    \n",
      "        for i,fp in enumerate(fps):\n",
      "            print i,\n",
      "            src_folder = os.path.split(fp)[0]\n",
      "            folder,dst_folder = os.path.split(src_folder)\n",
      "            date_folder = os.path.split(folder)[1]\n",
      "            try:\n",
      "                shutil.copytree(src_folder,os.path.join(target_folder,target_name,date_folder,dst_folder))\n",
      "            except WindowsError:\n",
      "                print 'Error copying fp {}'.format(fp)\n",
      "                skipped_fps.append(fp)\n",
      "\n",
      "    return skipped_fps\n",
      "    \n",
      "def collect_data_into_file(bs_folder, lt3_source_folder, lt4_source_folder, measurement_pattern):\n",
      "    fps_bs = tb.get_all_msmt_filepaths(bs_folder, pattern=measurement_pattern)\n",
      "    print 'Found {} filepaths'.format(len(fps_bs))\n",
      "    target_folder = os.path.split(bs_folder)[0]\n",
      "    fps_lt3, fps_lt4 = bell_data.get_lt_fps(fps_bs, lt3_source_folder, lt4_source_folder)\n",
      "    output_folder= os.path.split(bs_folder)[0]\n",
      "    output_file = os.path.join(output_folder,os.path.split(output_folder)[1]+'.hdf5')\n",
      "    f= h5py.File(output_file,'w')\n",
      "    ii=0\n",
      "    try:\n",
      "        for fp_bs,fp_lt3,fp_lt4 in zip(fps_bs,fps_lt3,fps_lt4):\n",
      "            if 'day5_run5.' in fp_bs:\n",
      "                continue\n",
      "            f_bs=h5py.File(fp_bs,'r')\n",
      "            f_lt3=h5py.File(fp_lt3,'r')\n",
      "            f_lt4=h5py.File(fp_lt4,'r')\n",
      "            try:\n",
      "                g=f.create_group(tb.get_msmt_name(f_bs))\n",
      "                g_bs=g.create_group('BS')\n",
      "                g_lt3=g.create_group('LT3')\n",
      "                g_lt4=g.create_group('LT4')\n",
      "                for k in f_bs.keys():\n",
      "                    if type(f_bs[k]) == h5py.Dataset:\n",
      "                        h5py.h5o.copy(f_bs.id,k,g_bs.id,k)#,copypl=h5py.h5p.PropID(h5py.h5o.COPY_SHALLOW_HIERARCHY_FLAG))\n",
      "                        h5py.h5o.copy(f_lt3.id,k,g_lt3.id,k)\n",
      "                        h5py.h5o.copy(f_lt4.id,k,g_lt4.id,k)\n",
      "            except Exception as e:\n",
      "                print f_bs\n",
      "                print e\n",
      "            f_bs.close()\n",
      "            f_lt3.close()\n",
      "            f_lt4.close()\n",
      "            ii+=1\n",
      "            if ii%10==0:\n",
      "                print ii,\n",
      "            f.flush()\n",
      "    finally:\n",
      "        f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bs_folder = r'D:\\measuring\\data\\2015-12-08-lhfbt6-new_detector\\BS'\n",
      "measurement_pattern = 'TheSecondFinal'\n",
      "lt3_source_folder = r'Y:\\data'#os.path.join(os.path.split(bs_folder)[0],'LT3')\n",
      "lt4_source_folder = r'L:\\NS\\qt\\Diamond\\Autobackup\\lt4\\data'#os.path.join(os.path.split(bs_folder)[0],'LT4')\n",
      "#fps_bs = tb.get_all_msmt_filepaths(bs_folder, pattern=measurement_pattern)\n",
      "#fps_lt3 = tb.get_all_msmt_filepaths(lt3_folder, pattern=measurement_pattern)\n",
      "#fps_lt4 = tb.get_all_msmt_filepaths(lt4_folder, pattern=measurement_pattern)\n",
      "#print fps_bs[69:80]\n",
      "#collect_data_into_file(bs_folder,lt3_folder,lt4_folder,measurement_pattern)\n",
      "collect_lt_data(bs_folder, lt3_source_folder, lt4_source_folder, measurement_pattern)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "folder=r'D:\\measuring\\data\\2015-06-28-lhfbt5\\BS\\20150701\\145112_Bell_BS_full_BellTheFinal_day5_run5'\n",
      "fp=tb.get_msmt_fp(folder)\n",
      "f=h5py.File(fp,'r')\n",
      "sn = f['/PQ_sync_number-1'].value \n",
      "sp = f['/PQ_special-1'].value      \n",
      "st = f['/PQ_sync_time-1'].value\n",
      "tt = f['/PQ_time-1'].value   \n",
      "ch = f['/PQ_channel-1'].value\n",
      "for k in f.keys():\n",
      "    print f[k]\n",
      "f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.sum((sp==1)&(ch==1))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bs_folder = r'D:\\measuring\\data\\2015-06-28-lhfbt5\\BS'\n",
      "measurement_pattern = 'TheFinal'\n",
      "lt3_folder = r'Y:\\data'\n",
      "lt4_folder = r'X:\\data'\n",
      "skipped = bell_data.collect_lt_data(bs_folder,lt3_folder,lt4_folder,measurement_pattern)\n",
      "print 'skipped', skipped"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bs_folder = r'D:\\measuring\\data'\n",
      "measurement_pattern = 'Bell_BS'\n",
      "\n",
      "output_folder = bs_folder\n",
      "analysis_fp = os.path.join(output_folder,tb.get_timestamp_from_now()+'_'+'total_events.hdf5')\n",
      "fps_bs = tb.get_all_msmt_filepaths(bs_folder, pattern=measurement_pattern)\n",
      "print len(fps_bs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bs_process_params = {\n",
      "\n",
      "    'st_start_ch0'            : 5430000-100000,\n",
      "    'st_len'                  : 350000 ,\n",
      "    'st_start_ch1'            : 5430000-100000,\n",
      "    'pulse_sep'               : 350000 ,  #XXXX\n",
      "\n",
      "    'hist_binsize_ps'\t\t  : 100, #ps \n",
      "    \n",
      "    }\n",
      "bell_data.process_tpqi_data(fps_bs, bs_process_params, analysis_fp,  \n",
      "                            update_previous_analysis_fp = None)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f = h5py.File(analysis_fp,'r')\n",
      "coincidences = f['analysis']['tpqi'].value\n",
      "f.close()\n",
      "\n",
      "st_start_ch0 = settings.analysis_params['st_start_ch0']\n",
      "st_len       = settings.analysis_params['st_len']\n",
      "st_start_ch1 = settings.analysis_params['st_start_ch1']\n",
      "p_sep        = 250000\n",
      "p_sep_2      = 350000\n",
      "st0=coincidences[:,be._cl_tpqi_st0]\n",
      "st1=coincidences[:,be._cl_tpqi_st1]\n",
      "st_fltr_0 = (((st_start_ch0<=st0)  & (st0<(st_start_ch0+st_len))) \\\n",
      "                 | ((st_start_ch0+p_sep<=st0) & (st0<(st_start_ch0+p_sep+st_len)))  \\\n",
      "                 | ((st_start_ch0+p_sep_2<=st0) & (st0<(st_start_ch0+p_sep_2+st_len))) )\n",
      "st_fltr_1 = (((st_start_ch1<=st1)  & (st1<(st_start_ch1+st_len))) \\\n",
      "                 | ((st_start_ch1+p_sep<=st1) & (st1<(st_start_ch1+p_sep+st_len))) \\\n",
      "                 | ((st_start_ch1+p_sep_2<=st1) & (st1<(st_start_ch1+p_sep_2+st_len))) )\n",
      "coincidences_fltr=coincidences[st_fltr_0 & st_fltr_1 ,be._cl_tpqi_dt]/1000.\n",
      "#coincidences_fltr=coincidences[: ,be._cl_tpqi_dt]/1000.\n",
      "dt=100\n",
      "center_peak = np.sum((coincidences_fltr>-dt) & (coincidences_fltr<dt))\n",
      "#print ii\n",
      "left_peak  =  np.sum(coincidences_fltr < -200)\n",
      "right_peak = np.sum(coincidences_fltr > 200)\n",
      "Vis = 1- float(center_peak)/(left_peak+right_peak)\n",
      "ax=plt.subplot(111)\n",
      "bins=np.linspace(-30,30,100)\n",
      "hist_TPQI, bins_TPQI, patches_TPQI = ax.hist(coincidences_fltr,bins=bins, color='b', cumulative=False, histtype = 'step')\n",
      "ax.set_title('TPQI histogram, V = {:.1f} % \\n {}'.format(Vis*100, btools.plot_title(analysis_fp)))\n",
      "ax.set_ylabel('Counts',fontsize = 15)\n",
      "ax.set_ylim(0,1.1*max(hist_TPQI))\n",
      "ax.tick_params(axis = 'y', labelsize = 13)\n",
      "ax.set_xlabel('Time [ns]',fontsize = 15)\n",
      "ax.tick_params(axis = 'x', labelsize = 13)\n",
      "#ax.text(-p_sep/1000,max(hist_TPQI),left_peak, horizontalalignment='center', verticalalignment ='bottom')\n",
      "#ax.text(+p_sep/1000,max(hist_TPQI),right_peak, horizontalalignment='center', verticalalignment ='bottom')\n",
      "ax.text(0,max(hist_TPQI),center_peak, horizontalalignment='center', verticalalignment ='bottom')\n",
      "btools.save_figure('TPQI', ax, output_folder, analysis_fp)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fps = [r'D:\\measuring\\data\\2015-06-28-lhfbt5\\BS\\20150627\\154419_Bell_BS_full_BellTheFinal_day2_run9\\154419_Bell_BS_full_BellTheFinal_day2_run9.hdf5',\n",
      "       r'D:\\measuring\\data\\2015-06-28-lhfbt5\\BS\\20150705\\210523_Bell_BS_full_BellTheFinal_day8_run8\\210523_Bell_BS_full_BellTheFinal_day8_run8.hdf5',\n",
      "       r'D:\\measuring\\data\\2015-06-28-lhfbt5\\BS\\20150708\\041634_Bell_BS_full_BellTheFinal_day10_run24\\041634_Bell_BS_full_BellTheFinal_day10_run24.hdf5',\n",
      "       r'D:\\measuring\\data\\2015-06-28-lhfbt5\\BS\\20150711\\071732_Bell_BS_full_BellTheFinal_day13_run34\\071732_Bell_BS_full_BellTheFinal_day13_run34.hdf5',\n",
      "       r'D:\\measuring\\data\\2015-06-28-lhfbt5\\BS\\20150711\\160654_Bell_BS_full_BellTheFinal_day14_run14\\160654_Bell_BS_full_BellTheFinal_day14_run14.hdf5',\n",
      "       r'D:\\measuring\\data\\2015-06-28-lhfbt5\\BS\\20150714\\040644_Bell_BS_full_BellTheFinal_day16_run28\\040644_Bell_BS_full_BellTheFinal_day16_run28.hdf5'\n",
      "       ]\n",
      "for fp in fps:\n",
      "    f=h5py.File(fp,'r')\n",
      "    sn = f['/PQ_sync_number-1'].value \n",
      "    sp = f['/PQ_special-1'].value      \n",
      "    st = f['/PQ_sync_time-1'].value\n",
      "    tt = f['/PQ_time-1'].value   \n",
      "    ch = f['/PQ_channel-1'].value\n",
      "    f.close()\n",
      "    is_ent_mkr = (sp==1) & (ch==1)\n",
      "    print os.path.split(fp)[1]\n",
      "    print 'difference last event and dataset end:'\n",
      "    print 'Syncs / 250: {:.2f}, total time: {:.1f} seconds'.format((sn[-1]-sn[is_ent_mkr][-1])/250., (tt[-1]-tt[is_ent_mkr][-1])/1e12)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "is_ent_mkr = (sp==1) & (ch==1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sn[-1]-sn[is_ent_mkr][-1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "72941/250."
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}
